{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kovac04/nets/blob/main/0_to_stable_diffusion/mnist_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "j1-BeC2dtz3J"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "cT2-2flat5jF",
    "outputId": "421ab045-69a0-436b-f4ef-d09d38012289"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "[ 0.  0.  0. 11.  8.  0.  0.  0.  0.  0.  6. 15.  2.  0.  0.  0.  0.  0.\n",
      " 13.  8.  0.  4.  7.  0.  0.  5. 16.  2.  2. 13.  9.  0.  0. 10. 15. 12.\n",
      " 15. 14.  1.  0.  0.  6. 16.  9. 16.  5.  0.  0.  0.  0.  0.  6. 14.  1.\n",
      "  0.  0.  0.  0.  0. 14.  7.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = load_digits()\n",
    "X,y = mnist.data, mnist.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "print(np.argmax(X_train[5]))\n",
    "plt.imshow(X_train[5].reshape(8,8),cmap='gray')\n",
    "print(X_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "plhLpQyxxz0C"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "# called it fish because why not\n",
    "class fishNet(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(fishNet, self).__init__()\n",
    "    self.l1 = nn.Linear(64,128) # given 128 neurons, with 64 random weights + 1 bias each\n",
    "    self.act = nn.ReLU()\n",
    "    self.l2 = nn.Linear(128,10)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = self.l1(x)\n",
    "    x = self.act(x)\n",
    "    x = self.l2(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4Sm1WgtAU3b",
    "outputId": "378f64d6-4cab-4849-8968-a71eed564f02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.7917,  3.1942, -0.8348, -1.9961,  1.0081,  2.8301, -2.1100,  0.0903,\n",
       "         -0.8790, -0.7444],\n",
       "        [ 1.4214,  4.0882,  0.3602, -2.3033,  1.5134,  1.5491,  0.8274,  0.3408,\n",
       "         -0.1784,  0.2421],\n",
       "        [ 1.2989,  3.8284,  0.1457, -1.9246,  0.2274,  2.7600,  0.0881, -0.3959,\n",
       "         -0.0087, -2.0487],\n",
       "        [ 0.9714,  3.0861, -0.5884, -0.3270,  0.0545,  3.4105,  0.9531,  0.7146,\n",
       "         -2.3115, -0.9671],\n",
       "        [ 2.3436,  3.4545, -1.0431, -1.7913,  0.7044,  3.1271,  0.0776,  0.6821,\n",
       "          0.4933, -1.0337],\n",
       "        [-0.2857,  2.0229,  1.0794, -1.8876,  0.9748,  2.8841,  1.2863,  0.1213,\n",
       "         -1.8266, -3.0221],\n",
       "        [ 2.5752,  5.0136, -0.9406, -1.6078,  0.9046,  2.7217, -1.2136,  0.9791,\n",
       "          0.4645, -0.9149],\n",
       "        [ 3.6343,  3.4758, -0.8439, -2.3131,  0.6363,  3.3278, -1.7781,  0.2557,\n",
       "         -0.5965, -1.3000],\n",
       "        [-0.3550,  2.5905,  0.4521, -1.1721,  0.2738,  2.7237, -0.8291, -1.0314,\n",
       "         -0.2273,  0.3338],\n",
       "        [-0.6608,  3.2881, -0.4530, -2.7400,  1.5605,  3.3361,  0.9085,  0.1244,\n",
       "         -0.7721, -2.2602]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = fishNet()\n",
    "model.forward(torch.tensor(X_train[:10]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4OgxzVG2HloZ",
    "outputId": "abd5bc30-1ee6-440b-cc00-ef3681718ea6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.00000 accuracy 1.00000: 100%|████████████████████████████████████████████████| 10000/10000 [00:15<00:00, 643.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "true label = 8, prediction = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "# take 32 example from X_train\n",
    "BS = 32\n",
    "loss_function = torch.nn.CrossEntropyLoss()     # cross entropy loss function for n categories\n",
    "optim = torch.optim.AdamW(model.parameters())   # adamW optimizer, with model's parameters\n",
    "for i in (t:=trange(10000)):\n",
    "  sample = np.random.randint(0,X_train.shape[0],size=BS,)  # 32 random ints * number of training examples\n",
    "  X_batch = X_train[sample]                 # select random training examples\n",
    "  y_batch = y_train[sample]                             # select those same labels\n",
    "  y_pred = model.forward(torch.tensor(X_batch).float()) # give 10 probabilities for each of 32 examples / 32x10 tensor\n",
    "  cat = torch.argmax(y_pred,dim=1)  # squish all cols into 1 col (32x1 tensor), store indices of max value in each column\n",
    "  accuracy = (cat == torch.tensor(y_batch)).float().mean()\n",
    "  loss = loss_function(y_pred,torch.tensor(y_batch))      # get loss on 32 current exam\n",
    "  optim.zero_grad()   # zero all gradients\n",
    "  loss.backward()     # backprop through loss function\n",
    "  optim.step()        # learn\n",
    "  t.set_description(\"loss %.5f accuracy %0.5f\"%(loss,accuracy))\n",
    "print(f\"\\ntrue label = {y_batch[0]}, prediction = {cat[0].item()}\")     # correct label and [wrong] probabilities for that example\n",
    "\n",
    "# 1. loss function computes the loss on the small batch\n",
    "# 2. set the gradient to zero\n",
    "# 3. take the derivatives of the loss function\n",
    "# 4. learn by stepping with the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Nu3uL_mIEco",
    "outputId": "f62ca695-ea34-451c-dab7-e4f8b504a41f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred = 1 , label = 1\n",
      "pred = 5 , label = 5\n",
      "pred = 0 , label = 0\n",
      "pred = 7 , label = 7\n",
      "pred = 1 , label = 1\n",
      "pred = 0 , label = 0\n",
      "pred = 6 , label = 6\n",
      "pred = 1 , label = 1\n",
      "pred = 5 , label = 5\n",
      "pred = 4 , label = 4\n",
      "pred = 9 , label = 9\n",
      "pred = 2 , label = 2\n",
      "pred = 7 , label = 7\n",
      "pred = 8 , label = 8\n",
      "pred = 4 , label = 4\n",
      "pred = 6 , label = 6\n",
      "pred = 9 , label = 9\n",
      "pred = 3 , label = 3\n",
      "pred = 7 , label = 7\n",
      "pred = 4 , label = 4\n",
      "pred = 7 , label = 7\n",
      "pred = 1 , label = 1\n",
      "pred = 8 , label = 8\n",
      "pred = 6 , label = 6\n",
      "pred = 0 , label = 0\n",
      "pred = 9 , label = 9\n",
      "pred = 6 , label = 6\n",
      "pred = 1 , label = 1\n",
      "pred = 3 , label = 3\n",
      "pred = 7 , label = 7\n",
      "pred = 5 , label = 5\n",
      "pred = 9 , label = 9\n",
      "pred = 8 , label = 8\n",
      "pred = 3 , label = 3\n",
      "pred = 2 , label = 2\n",
      "pred = 8 , label = 8\n",
      "pred = 8 , label = 8\n",
      "pred = 1 , label = 1\n",
      "pred = 1 , label = 1\n",
      "pred = 0 , label = 0\n",
      "pred = 7 , label = 7\n",
      "pred = 9 , label = 9\n",
      "pred = 0 , label = 0\n",
      "pred = 0 , label = 0\n",
      "pred = 8 , label = 8\n",
      "pred = 7 , label = 7\n",
      "pred = 2 , label = 2\n",
      "pred = 7 , label = 7\n",
      "pred = 4 , label = 4\n",
      "pred = 3 , label = 3\n",
      "pred = 4 , label = 4\n",
      "pred = 3 , label = 3\n",
      "pred = 4 , label = 4\n",
      "pred = 0 , label = 0\n",
      "pred = 4 , label = 4\n",
      "pred = 7 , label = 7\n",
      "pred = 0 , label = 0\n",
      "pred = 5 , label = 5\n",
      "pred = 5 , label = 5\n",
      "pred = 5 , label = 5\n",
      "pred = 2 , label = 2\n",
      "pred = 1 , label = 1\n",
      "pred = 7 , label = 7\n",
      "pred = 0 , label = 0\n",
      "pred = 5 , label = 5\n",
      "pred = 1 , label = 1\n",
      "pred = 8 , label = 8\n",
      "pred = 3 , label = 3\n",
      "pred = 3 , label = 3\n",
      "pred = 4 , label = 4\n",
      "pred = 0 , label = 0\n",
      "pred = 3 , label = 3\n",
      "pred = 7 , label = 7\n",
      "pred = 4 , label = 4\n",
      "pred = 3 , label = 3\n",
      "pred = 4 , label = 4\n",
      "pred = 2 , label = 2\n",
      "pred = 9 , label = 9\n",
      "pred = 7 , label = 7\n",
      "pred = 3 , label = 3\n",
      "pred = 2 , label = 2\n",
      "pred = 5 , label = 5\n",
      "pred = 3 , label = 3\n",
      "pred = 4 , label = 4\n",
      "pred = 1 , label = 1\n",
      "pred = 5 , label = 5\n",
      "pred = 5 , label = 5\n",
      "pred = 2 , label = 2\n",
      "pred = 1 , label = 5\n",
      "88\n",
      "pred = 2 , label = 2\n",
      "pred = 2 , label = 2\n",
      "pred = 2 , label = 2\n",
      "pred = 2 , label = 2\n",
      "pred = 7 , label = 7\n",
      "pred = 0 , label = 0\n",
      "pred = 8 , label = 8\n",
      "pred = 1 , label = 1\n",
      "pred = 7 , label = 7\n",
      "pred = 4 , label = 4\n",
      "pred = 2 , label = 2\n",
      "0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "\n",
    "y_preds_final = torch.argmax(model.forward(torch.tensor(X_test).float()) , dim=1).numpy()\n",
    "eval = (y_preds_final == y_test).mean()\n",
    "for i in range(100):\n",
    "  print(f\"pred = {y_preds_final[i]} , label = {y_test[i]}\")\n",
    "  if(y_preds_final[i] != y_test[i]):print(i)\n",
    "print(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPfgbDbVRvgkxsZgkFowNzq",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
